{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import psycopg2\nimport pandas as pd\nfrom simpletransformers.classification import MultiLabelClassificationModel\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport optuna\nfrom sklearn.metrics import label_ranking_average_precision_score\nfrom simpletransformers.classification import ClassificationArgs","metadata":{"execution":{"iopub.status.busy":"2022-06-18T14:18:07.343525Z","iopub.execute_input":"2022-06-18T14:18:07.343903Z","iopub.status.idle":"2022-06-18T14:18:07.349347Z","shell.execute_reply.started":"2022-06-18T14:18:07.343872Z","shell.execute_reply":"2022-06-18T14:18:07.348336Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"con = psycopg2.connect(\n  database=\"db_dsa\", \n  user=\"udsa\", \n  password=\"P@ssword2021\", \n  host=\"92.242.58.173\", \n  port=\"1984\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T14:08:09.411193Z","iopub.execute_input":"2022-06-18T14:08:09.411897Z","iopub.status.idle":"2022-06-18T14:08:10.442514Z","shell.execute_reply.started":"2022-06-18T14:08:09.411856Z","shell.execute_reply":"2022-06-18T14:08:10.441700Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"cur = con.cursor()\ncur.execute(\"SELECT * from PROJECTS\")\nrows = cur.fetchall()\ncolumn_names=[\"ID\",\"NUMBER\",\"VACANCIES\",\"NAME\",\"TYPE\",\"TYPEDESC\",\"TYPEID\",\"STATUSID\", \"STATUSDESC\",\"DIRECTIONHEAD\",\"HEAD\",\"DATACREATED\",\"FACULTYID\"]\ndf = pd.DataFrame(rows, columns=column_names)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T14:08:10.444178Z","iopub.execute_input":"2022-06-18T14:08:10.444565Z","iopub.status.idle":"2022-06-18T14:08:11.818872Z","shell.execute_reply.started":"2022-06-18T14:08:10.444529Z","shell.execute_reply":"2022-06-18T14:08:11.818128Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"    ID  NUMBER  VACANCIES                                               NAME  \\\n0  205     NaN          2  Численное и аналитическое исследование эффекта...   \n1  208     NaN          3  Исследование механизмов образования, способов ...   \n2  215     NaN          1                  Разработка моста переменного тока   \n3  216     NaN          3  Разработка нательных антенн и излучателей для ...   \n4  218     NaN          0  Разработка глоссария физических терминов для м...   \n\n        TYPE        TYPEDESC  TYPEID  STATUSID      STATUSDESC  \\\n0        nir             НИР       1         1  Готов к работе   \n1        nir             НИР       1         1  Готов к работе   \n2  soft-hard  Прогр-аппарат.       3         1  Готов к работе   \n3  soft-hard  Прогр-аппарат.       3         1  Готов к работе   \n4       soft          Прогр.       2         1  Готов к работе   \n\n                  DIRECTIONHEAD                            HEAD  \\\n0  Данилов Владимир Григорьевич    Данилов Владимир Григорьевич   \n1                                                Грачев Николай   \n2                                             Балакин Станислав   \n3   Елизаров Андрей Альбертович                 Скуридин Андрей   \n4                                Гузенкова Александра Сергеевна   \n\n           DATACREATED FACULTYID  \n0  08.05.2020 21:25:02      None  \n1  11.05.2020 14:07:40      None  \n2  13.05.2020 16:41:39      None  \n3  13.05.2020 17:00:19      None  \n4  13.05.2020 19:38:43      None  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>NUMBER</th>\n      <th>VACANCIES</th>\n      <th>NAME</th>\n      <th>TYPE</th>\n      <th>TYPEDESC</th>\n      <th>TYPEID</th>\n      <th>STATUSID</th>\n      <th>STATUSDESC</th>\n      <th>DIRECTIONHEAD</th>\n      <th>HEAD</th>\n      <th>DATACREATED</th>\n      <th>FACULTYID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>205</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>Численное и аналитическое исследование эффекта...</td>\n      <td>nir</td>\n      <td>НИР</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Готов к работе</td>\n      <td>Данилов Владимир Григорьевич</td>\n      <td>Данилов Владимир Григорьевич</td>\n      <td>08.05.2020 21:25:02</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>208</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Исследование механизмов образования, способов ...</td>\n      <td>nir</td>\n      <td>НИР</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Готов к работе</td>\n      <td></td>\n      <td>Грачев Николай</td>\n      <td>11.05.2020 14:07:40</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>215</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Разработка моста переменного тока</td>\n      <td>soft-hard</td>\n      <td>Прогр-аппарат.</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Готов к работе</td>\n      <td></td>\n      <td>Балакин Станислав</td>\n      <td>13.05.2020 16:41:39</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>216</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Разработка нательных антенн и излучателей для ...</td>\n      <td>soft-hard</td>\n      <td>Прогр-аппарат.</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Готов к работе</td>\n      <td>Елизаров Андрей Альбертович</td>\n      <td>Скуридин Андрей</td>\n      <td>13.05.2020 17:00:19</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>218</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Разработка глоссария физических терминов для м...</td>\n      <td>soft</td>\n      <td>Прогр.</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Готов к работе</td>\n      <td></td>\n      <td>Гузенкова Александра Сергеевна</td>\n      <td>13.05.2020 19:38:43</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"papers = pd.DataFrame({\n    'title': df['NAME'].tolist(),\n    'categories': df['TYPE'].tolist()\n})\n\npapers['title'] = papers['title'].apply(lambda x: x.replace(\"\\n\",\"\"))\npapers['title'] = papers['title'].apply(lambda x: x.strip())\npapers['text'] = papers['title']\n\npapers['categories'] = papers['categories'].apply(lambda x: tuple(x.split()))\n\nshortlisted_categories = papers['categories'].value_counts().reset_index(name=\"count\").query(\"count > 1\")[\"index\"].tolist()\npapers = papers[papers[\"categories\"].isin(shortlisted_categories)].reset_index(drop=True)\n\npapers = papers.sample(frac=1).reset_index(drop=True)\n\npapers = papers.groupby('categories').head(250).reset_index(drop=True)\n\nmulti_label_encoder = MultiLabelBinarizer()\nmulti_label_encoder.fit(papers['categories'])\npapers['categories_encoded'] = papers['categories'].apply(lambda x: multi_label_encoder.transform([x])[0])\n\npapers = papers[[\"text\", \"categories\", \"categories_encoded\"]]\npapers.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T14:08:11.820722Z","iopub.execute_input":"2022-06-18T14:08:11.821070Z","iopub.status.idle":"2022-06-18T14:08:11.883632Z","shell.execute_reply.started":"2022-06-18T14:08:11.821035Z","shell.execute_reply":"2022-06-18T14:08:11.882775Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                text    categories  \\\n0  Программно-аппаратный комплекс для распознаван...  (soft-hard,)   \n1  Равновесные конфигурации точечных вихрей на пл...        (nir,)   \n2                          Мобильное приложение МИЭМ       (soft,)   \n3                                  Студия самозаписи       (soft,)   \n4  Разработка системы VR-визуализации для центра ...       (soft,)   \n\n  categories_encoded  \n0          [0, 0, 1]  \n1          [1, 0, 0]  \n2          [0, 1, 0]  \n3          [0, 1, 0]  \n4          [0, 1, 0]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>categories</th>\n      <th>categories_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Программно-аппаратный комплекс для распознаван...</td>\n      <td>(soft-hard,)</td>\n      <td>[0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Равновесные конфигурации точечных вихрей на пл...</td>\n      <td>(nir,)</td>\n      <td>[1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Мобильное приложение МИЭМ</td>\n      <td>(soft,)</td>\n      <td>[0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Студия самозаписи</td>\n      <td>(soft,)</td>\n      <td>[0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Разработка системы VR-визуализации для центра ...</td>\n      <td>(soft,)</td>\n      <td>[0, 1, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train, test = train_test_split(papers, test_size=0.3, stratify=papers['categories'], random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T14:08:11.884980Z","iopub.execute_input":"2022-06-18T14:08:11.885332Z","iopub.status.idle":"2022-06-18T14:08:11.893627Z","shell.execute_reply.started":"2022-06-18T14:08:11.885299Z","shell.execute_reply":"2022-06-18T14:08:11.892869Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-8, 1e-4, log = True)\n    adam_epsilon = trial.suggest_float(\"adam_epilson\", 1e-8, 1e-4, log = True)\n    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 1, 3)\n\n    model_args = {\n        'sliding_window':False,\n        'learning_rate':learning_rate,\n        'adam_epsilon':adam_epsilon,\n        'train_batch_size':8,\n        'eval_batch_size':4,\n        'num_train_epochs':num_train_epochs,\n        'do_lower_case':False,\n        'max_seq_length':512,\n        'overwrite_output_dir':True\n    }\n    model = MultiLabelClassificationModel('bert', \n                                      'bert-base-cased', \n                                      num_labels=len(shortlisted_categories), \n                                      args=model_args, use_cuda=True)\n\n    model.train_model(train[['text', 'categories_encoded']])\n    result, model_outputs, wrong_predictions = model.eval_model(test[['text', 'categories_encoded']])\n    return result['LRAP']","metadata":{"execution":{"iopub.status.busy":"2022-06-18T14:24:06.085292Z","iopub.execute_input":"2022-06-18T14:24:06.085644Z","iopub.status.idle":"2022-06-18T14:24:06.093754Z","shell.execute_reply.started":"2022-06-18T14:24:06.085616Z","shell.execute_reply":"2022-06-18T14:24:06.092875Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(study_name=\"bertmodel\")\nstudy.optimize(objective, n_trials=10)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T14:24:07.301677Z","iopub.execute_input":"2022-06-18T14:24:07.302018Z","iopub.status.idle":"2022-06-18T14:30:45.234090Z","shell.execute_reply.started":"2022-06-18T14:24:07.301990Z","shell.execute_reply":"2022-06-18T14:30:45.233108Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-06-18 14:24:07,303]\u001b[0m A new study created in memory with name: bertmodel\u001b[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3510f71f1af849e3a466f4f0aa997abc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52c597884ad74f3b99f166cadecb7d5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 2:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79cca508e7e44dfb91c5e74b3a2e8793"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 2:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7eb313c177914e27b2807312a382e352"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"530edb6e83514ba994e0c058b4f6e4ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69f6801144564f3cb18890c2c643305e"}},"metadata":{}},{"name":"stderr","text":"\u001b[32m[I 2022-06-18 14:24:48,710]\u001b[0m Trial 0 finished with value: 0.6924398625429554 and parameters: {'learning_rate': 7.5865871539631025e-06, 'adam_epilson': 3.970233987183694e-06, 'num_train_epochs': 2}. Best is trial 0 with value: 0.6924398625429554.\u001b[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8be48c200c794fbbb5b062a1181398bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef29a1add6ba45f5b0a296d5716360f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea4e598212594d7dbfe0ce172ca29086"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b0161815b134a9bbf0412f0f271d68c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e463b396c5bb4b12a96e681171d89d74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8040fca7a4d94bd0a1753909abf06fe5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c92848e921124318a3e5563cac9a48ee"}},"metadata":{}},{"name":"stderr","text":"\u001b[32m[I 2022-06-18 14:25:45,709]\u001b[0m Trial 1 finished with value: 0.7439862542955324 and parameters: {'learning_rate': 1.061052758418945e-05, 'adam_epilson': 6.502048370120701e-06, 'num_train_epochs': 3}. Best is trial 0 with value: 0.6924398625429554.\u001b[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b997ef87966a4c94ac4e480eb6d9bed4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e16fd5513dc04137acdb2b6e65d42492"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dc2d4d9e6a84e12869ab9acef8215a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"218d7eaf29df4a659ae6922771285593"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"132cd08d4d654896904433ed03bbfea6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccc7643b662440d09394f38c1b57aa05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a46d2b49e62f4c0886af06b46ea24845"}},"metadata":{}},{"name":"stderr","text":"\u001b[32m[I 2022-06-18 14:26:46,756]\u001b[0m Trial 2 finished with value: 0.5704467353951894 and parameters: {'learning_rate': 5.7174874388922874e-08, 'adam_epilson': 3.0486577585239304e-08, 'num_train_epochs': 3}. Best is trial 2 with value: 0.5704467353951894.\u001b[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75625ff6821e4f109b1b6b57b283255b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b39f27448f243ba84c5f79522f8943a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 1:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c8c3d79e94c4aa7a8e74474a0d8c270"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1118577fa086441ca5fc1476b8945a76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5713dc8c66474d3fa2237a34d23e7f5f"}},"metadata":{}},{"name":"stderr","text":"\u001b[32m[I 2022-06-18 14:27:11,028]\u001b[0m Trial 3 finished with value: 0.7491408934707902 and parameters: {'learning_rate': 1.797779845636144e-05, 'adam_epilson': 3.7137826992178445e-07, 'num_train_epochs': 1}. Best is trial 2 with value: 0.5704467353951894.\u001b[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2adc0bd00f67439c81f35a8d1edcfa32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d4c73e20756488fb9490551ba35176b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2f5a42544114fdeaf7492fe2fe95a5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd45d345797e4100897c84073b8a4a48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"402a706d15cd40b8be98700316bda1a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2946e3640526496b8d116ec1df46b49b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c027308a5a284efab6bf794d9199090c"}},"metadata":{}},{"name":"stderr","text":"\u001b[32m[I 2022-06-18 14:28:08,594]\u001b[0m Trial 4 finished with value: 0.7388316151202746 and parameters: {'learning_rate': 9.358441168510587e-06, 'adam_epilson': 1.796760280330473e-08, 'num_train_epochs': 3}. Best is trial 2 with value: 0.5704467353951894.\u001b[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e8887a677e7456eb0a641fea443cb1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2f0193efdd74ebc99cdbf8d80c910bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 1:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"180612d23f7b49fcb00dad738e9a8189"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f84988c883b4103a715f483739337a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc0c000ef9e34e87a996fbf5c2c0c064"}},"metadata":{}},{"name":"stderr","text":"\u001b[32m[I 2022-06-18 14:28:33,668]\u001b[0m Trial 5 finished with value: 0.7371134020618557 and parameters: {'learning_rate': 8.908924155888807e-06, 'adam_epilson': 5.308319888081597e-08, 'num_train_epochs': 1}. Best is trial 2 with value: 0.5704467353951894.\u001b[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77deb89f37b540a291f37de68eb54d58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f925016880bf4a9798ac935de6f71594"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 1:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da32acbeefe04034b99527b409fa403d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2a986a2911b4798bbd1ea085590a142"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bcbf17168964ee0a7cb79f98041c84e"}},"metadata":{}},{"name":"stderr","text":"\u001b[32m[I 2022-06-18 14:28:58,101]\u001b[0m Trial 6 finished with value: 0.6357388316151203 and parameters: {'learning_rate': 1.3004733010056525e-08, 'adam_epilson': 2.535753955313889e-05, 'num_train_epochs': 1}. Best is trial 2 with value: 0.5704467353951894.\u001b[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9adf4eaeb7594a2a9f0bc69379441f6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30873c099b4d471c87cec1fc034d67ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7075ffe90bf43f9933796b47121174a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b091abed562f44f6befe93f2e21121f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b52a94da91d46cbaa1f092ef0444c7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a19ae8161e1423485919aabba6ebaf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d6dc5ff82164bf6bc95ac134c2b8979"}},"metadata":{}},{"name":"stderr","text":"\u001b[32m[I 2022-06-18 14:29:55,531]\u001b[0m Trial 7 finished with value: 0.4828178694158077 and parameters: {'learning_rate': 4.390522616377003e-08, 'adam_epilson': 2.0560687727873848e-06, 'num_train_epochs': 3}. Best is trial 7 with value: 0.4828178694158077.\u001b[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7efb363816cd4c678aeee6be49acc2bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f7eed437a574170acbe86c06a1096eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 1:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21189f54b2a944f6ac6448e3c5c80390"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"016c441faab64fbe8eae54eec8cce701"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1c03fd8c6f2490a8b0f92c3099ccfc8"}},"metadata":{}},{"name":"stderr","text":"\u001b[32m[I 2022-06-18 14:30:20,468]\u001b[0m Trial 8 finished with value: 0.7388316151202746 and parameters: {'learning_rate': 1.3727923530236275e-05, 'adam_epilson': 2.268473702749702e-06, 'num_train_epochs': 1}. Best is trial 7 with value: 0.4828178694158077.\u001b[0m\nSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"875e204d64cf4a6c987cb8f627043958"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3f74a895269446d8030c2ee2cc14ba9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 1:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e4c8f8752d84cb6b561e5ad3c9bac7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/97 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9a818416e514705ae49433f251d9aef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa20ad719e2843279fb7ca448518cf36"}},"metadata":{}},{"name":"stderr","text":"\u001b[32m[I 2022-06-18 14:30:45,230]\u001b[0m Trial 9 finished with value: 0.7439862542955324 and parameters: {'learning_rate': 7.397883093249875e-06, 'adam_epilson': 2.9272114179501076e-05, 'num_train_epochs': 1}. Best is trial 7 with value: 0.4828178694158077.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Best Params : {}\".format(study.best_params))\n\nprint(\"Best LRAP : {}\".format(study.best_value))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T14:45:55.326381Z","iopub.execute_input":"2022-06-18T14:45:55.327234Z","iopub.status.idle":"2022-06-18T14:45:55.333097Z","shell.execute_reply.started":"2022-06-18T14:45:55.327167Z","shell.execute_reply":"2022-06-18T14:45:55.332279Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Best Params : {'learning_rate': 4.390522616377003e-08, 'adam_epilson': 2.0560687727873848e-06, 'num_train_epochs': 3}\nBest LRAP : 0.4828178694158077\n","output_type":"stream"}]},{"cell_type":"code","source":"study.best_trial","metadata":{"execution":{"iopub.status.busy":"2022-06-18T14:47:23.800804Z","iopub.execute_input":"2022-06-18T14:47:23.801159Z","iopub.status.idle":"2022-06-18T14:47:23.807651Z","shell.execute_reply.started":"2022-06-18T14:47:23.801130Z","shell.execute_reply":"2022-06-18T14:47:23.806910Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"FrozenTrial(number=7, values=[0.4828178694158077], datetime_start=datetime.datetime(2022, 6, 18, 14, 28, 58, 102774), datetime_complete=datetime.datetime(2022, 6, 18, 14, 29, 55, 531484), params={'learning_rate': 4.390522616377003e-08, 'adam_epilson': 2.0560687727873848e-06, 'num_train_epochs': 3}, distributions={'learning_rate': LogUniformDistribution(high=0.0001, low=1e-08), 'adam_epilson': LogUniformDistribution(high=0.0001, low=1e-08), 'num_train_epochs': IntUniformDistribution(high=3, low=1, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=7, state=TrialState.COMPLETE, value=None)"},"metadata":{}}]}]}
